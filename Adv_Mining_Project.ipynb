{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Topic Models\n",
    "In this project, we will analyze the 20 newsgroup dataset (http://qwone.com/jason/20Newsgroups/) using topic models. We consider all the articles in the following two news groups: comp.sys.ibm.pc.hardware and comp.sys.mac.hardware.\n",
    "\n",
    "Removing the stopwords from the vocabulary and further limiting the vocabulary to the top 1000 most frequent terms, we can now summarize the N_train training articles and N_test testing articles into a 1000×(N_train +N_test) word frequency count matrix. \n",
    "\n",
    "Denote this matrix as X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "hardware_train = fetch_20newsgroups(subset='train', categories =['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware'])\n",
    "hardware_test = fetch_20newsgroups(subset='test', categories =['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Use tf as the feature for each document. Train a binary logistic regression model on the training set. Evaluate its document classification accuracy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train vector shape: (1168, 1000)\n",
      "test vector shape: (777, 1000)\n",
      "f1_score 0.8712826017811705\n",
      "accuracy: 0.8712998712998713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# get stopwords list\n",
    "stopwords = open(\"stopwords.txt\").read().replace('\\n', ' ').split()\n",
    "\n",
    "# vectorize and transform traning data using tf as the feature\n",
    "tf_vectorizer = TfidfVectorizer(use_idf=False, \n",
    "                                max_features=1000, \n",
    "                                stop_words = stopwords)\n",
    "\n",
    "tf_vectors = tf_vectorizer.fit_transform(hardware_train.data)\n",
    "\n",
    "print(\"train vector shape:\", tf_vectors.shape)\n",
    "\n",
    "# MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# vectorize test data\n",
    "tf_vectors_test = tf_vectorizer.transform(hardware_test.data)\n",
    "print(\"test vector shape:\", tf_vectors_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# train\n",
    "tf_clf = LogisticRegression(solver='lbfgs')\n",
    "tf_clf.fit(tf_vectors, hardware_train.target)\n",
    "\n",
    "# predict\n",
    "tf_pred = tf_clf.predict(tf_vectors_test)\n",
    "print(\"f1_score\", f1_score(hardware_test.target,tf_pred,average='macro'))\n",
    "print(\"accuracy:\", accuracy_score(hardware_test.target, tf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Use tf-idf as the feature for each document and repeat Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.8815799936386769\n",
      "accuracy: 0.8815958815958816\n"
     ]
    }
   ],
   "source": [
    "# vectorize and transform traning data using tf as the feature\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, \n",
    "                                max_features=1000, \n",
    "                                stop_words = stopwords)\n",
    "\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(hardware_train.data)\n",
    "\n",
    "# vectorize test data\n",
    "tfidf_vectors_test = tfidf_vectorizer.transform(hardware_test.data)\n",
    "\n",
    "# train\n",
    "tfidf_clf = LogisticRegression(solver='lbfgs')\n",
    "tfidf_clf.fit(tfidf_vectors, hardware_train.target)\n",
    "\n",
    "# predict\n",
    "tfidf_pred = tfidf_clf.predict(tfidf_vectors_test)\n",
    "print(\"f1_score\", f1_score(hardware_test.target,tfidf_pred, average='macro'))\n",
    "print(\"accuracy:\", accuracy_score(hardware_test.target, tfidf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Decompose X into USV T using SVD, where we set the dimension of U as 1000×20. Using SV T as the document features and repeat Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1168, 1000)\n",
      "(777, 1000)\n"
     ]
    }
   ],
   "source": [
    "#TODO: we don't have X yet\n",
    "print(type(tf_vectors))\n",
    "print(type(tf_vectors_test))\n",
    "print(tf_vectors.shape)\n",
    "print(tf_vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
